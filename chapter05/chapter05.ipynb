{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2146ab9-1129-4b18-9dc5-6fda23c11e29",
   "metadata": {},
   "source": [
    "## 第5章: 係り受け解析\n",
    "日本語Wikipediaの「人工知能」に関する記事からテキスト部分を抜き出したファイルがai.ja.zipに収録されている． この文章をCaboChaやKNP等のツールを利用して係り受け解析を行い，その結果をai.ja.txt.parsedというファイルに保存せよ．このファイルを読み込み，以下の問に対応するプログラムを実装せよ．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380f60ae-19fa-4a8d-ade6-3d7f8b703c26",
   "metadata": {},
   "source": [
    "### 40. 係り受け解析結果の読み込み（形態素）\n",
    "形態素を表すクラスMorphを実装せよ．このクラスは表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をメンバ変数に持つこととする．さらに，係り受け解析の結果（ai.ja.txt.parsed）を読み込み，各文をMorphオブジェクトのリストとして表現し，冒頭の説明文の形態素列を表示せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e587c9e2-0d10-48c2-baa7-c926b50d6924",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Morph:\n",
    "    def __init__(self, surface, base, pos, pos1):\n",
    "        self.surface = surface\n",
    "        self.base = base\n",
    "        self.pos = pos\n",
    "        self.pos1 = pos1\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"surface: {self.surface}, base: {self.base}, pos: {self.pos}, pos1: {self.pos1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "899048b9-9c5f-4d4e-a994-7b076c808d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surface: 人工, base: 人工, pos: 名詞, pos1: 一般\n",
      "surface: 知能, base: 知能, pos: 名詞, pos1: 一般\n",
      "\n",
      "\n",
      "surface: 人工, base: 人工, pos: 名詞, pos1: 一般\n",
      "surface: 知能, base: 知能, pos: 名詞, pos1: 一般\n",
      "surface: （, base: （, pos: 記号, pos1: 括弧開\n",
      "surface: じん, base: じん, pos: 名詞, pos1: 一般\n",
      "surface: こうち, base: こうち, pos: 名詞, pos1: 一般\n",
      "surface: のう, base: のう, pos: 助詞, pos1: 終助詞\n",
      "surface: 、, base: 、, pos: 記号, pos1: 読点\n",
      "surface: 、, base: 、, pos: 記号, pos1: 読点\n",
      "surface: AI, base: *, pos: 名詞, pos1: 一般\n",
      "surface: 〈, base: 〈, pos: 記号, pos1: 括弧開\n",
      "surface: エーアイ, base: *, pos: 名詞, pos1: 固有名詞\n",
      "surface: 〉, base: 〉, pos: 記号, pos1: 括弧閉\n",
      "surface: ）, base: ）, pos: 記号, pos1: 括弧閉\n",
      "surface: と, base: と, pos: 助詞, pos1: 格助詞\n",
      "surface: は, base: は, pos: 助詞, pos1: 係助詞\n",
      "surface: 、, base: 、, pos: 記号, pos1: 読点\n",
      "surface: 「, base: 「, pos: 記号, pos1: 括弧開\n",
      "surface: 『, base: 『, pos: 記号, pos1: 括弧開\n",
      "surface: 計算, base: 計算, pos: 名詞, pos1: サ変接続\n",
      "surface: （, base: （, pos: 記号, pos1: 括弧開\n",
      "surface: ）, base: ）, pos: 記号, pos1: 括弧閉\n",
      "surface: 』, base: 』, pos: 記号, pos1: 括弧閉\n",
      "surface: という, base: という, pos: 助詞, pos1: 格助詞\n",
      "surface: 概念, base: 概念, pos: 名詞, pos1: 一般\n",
      "surface: と, base: と, pos: 助詞, pos1: 並立助詞\n",
      "surface: 『, base: 『, pos: 記号, pos1: 括弧開\n",
      "surface: コンピュータ, base: コンピュータ, pos: 名詞, pos1: 一般\n",
      "surface: （, base: （, pos: 記号, pos1: 括弧開\n",
      "surface: ）, base: ）, pos: 記号, pos1: 括弧閉\n",
      "surface: 』, base: 』, pos: 記号, pos1: 括弧閉\n",
      "surface: という, base: という, pos: 助詞, pos1: 格助詞\n",
      "surface: 道具, base: 道具, pos: 名詞, pos1: 一般\n",
      "surface: を, base: を, pos: 助詞, pos1: 格助詞\n",
      "surface: 用い, base: 用いる, pos: 動詞, pos1: 自立\n",
      "surface: て, base: て, pos: 助詞, pos1: 接続助詞\n",
      "surface: 『, base: 『, pos: 記号, pos1: 括弧開\n",
      "surface: 知能, base: 知能, pos: 名詞, pos1: 一般\n",
      "surface: 』, base: 』, pos: 記号, pos1: 括弧閉\n",
      "surface: を, base: を, pos: 助詞, pos1: 格助詞\n",
      "surface: 研究, base: 研究, pos: 名詞, pos1: サ変接続\n",
      "surface: する, base: する, pos: 動詞, pos1: 自立\n",
      "surface: 計算, base: 計算, pos: 名詞, pos1: サ変接続\n",
      "surface: 機, base: 機, pos: 名詞, pos1: 接尾\n",
      "surface: 科学, base: 科学, pos: 名詞, pos1: 一般\n",
      "surface: （, base: （, pos: 記号, pos1: 括弧開\n",
      "surface: ）, base: ）, pos: 記号, pos1: 括弧閉\n",
      "surface: の, base: の, pos: 助詞, pos1: 連体化\n",
      "surface: 一, base: 一, pos: 名詞, pos1: 数\n",
      "surface: 分野, base: 分野, pos: 名詞, pos1: 一般\n",
      "surface: 」, base: 」, pos: 記号, pos1: 括弧閉\n",
      "surface: を, base: を, pos: 助詞, pos1: 格助詞\n",
      "surface: 指す, base: 指す, pos: 動詞, pos1: 自立\n",
      "surface: 語, base: 語, pos: 名詞, pos1: 一般\n",
      "surface: 。, base: 。, pos: 記号, pos1: 句点\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "with open(\"ai.ja.txt.parsed\", \"r\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "    sentences_m = []\n",
    "    s = []\n",
    "    # sentences: [[s1], [s2], ...] or [[m11 m12 ...], [m21 m22 ...], ...]\n",
    "    for line in lines:\n",
    "        if re.search(r\"^\\*.*\", line):\n",
    "            # ignore line that start with '*'\n",
    "            continue\n",
    "            \n",
    "        if line == \"EOS\":\n",
    "            # end current sentence; start new sentence\n",
    "            if len(s) != 0:\n",
    "                sentences_m.append(s)\n",
    "                s = []\n",
    "        else:\n",
    "            # append a morph object\n",
    "            cols = re.split(r\"\\t|,\", line)\n",
    "            s.append(Morph(cols[0],cols[7],cols[1],cols[2]))\n",
    "            if cols[0] == \"。\":\n",
    "                sentences_m.append(s)\n",
    "                s = []\n",
    "\n",
    "# first element in the list is \"人工知能\" (title)\n",
    "for sentence in sentences_m[:2]:\n",
    "    for morph in sentence:\n",
    "        print(morph)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68eb9a4a-d3a1-4f60-a705-1d94a1bd28ac",
   "metadata": {},
   "source": [
    "### 41. 係り受け解析結果の読み込み（文節・係り受け）\n",
    "40に加えて，文節を表すクラスChunkを実装せよ．このクラスは形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つこととする．さらに，入力テキストの係り受け解析結果を読み込み，１文をChunkオブジェクトのリストとして表現し，冒頭の説明文の文節の文字列と係り先を表示せよ．本章の残りの問題では，ここで作ったプログラムを活用せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dada067f-fa42-4df9-b21f-ec7925151685",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunk:\n",
    "    def __init__(self, index, morphs=[], dst=None, srcs=[]):\n",
    "        self.index = index # added: 文節番号\n",
    "        self.morphs = morphs\n",
    "        self.dst = dst\n",
    "        self.srcs = srcs\n",
    "    \n",
    "    def __str__(self):\n",
    "        morphs_rep = \" \".join([m.surface for m in self.morphs])\n",
    "        return f\"morphs: {morphs_rep}, dst: {self.dst}, srcs: {self.srcs}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c15decd7-e9ad-4c07-8985-bb720d23e2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morphs: 人工 知能, dst: -1, srcs: []\n",
      "\n",
      "\n",
      "morphs: 人工 知能, dst: 17, srcs: []\n",
      "morphs: （ じん こうち のう 、 、, dst: 17, srcs: []\n",
      "morphs: AI, dst: 3, srcs: []\n",
      "morphs: 〈 エーアイ 〉 ） と は 、, dst: 17, srcs: [2]\n",
      "morphs: 「 『 計算, dst: 5, srcs: []\n",
      "morphs: （ ） 』 という, dst: 9, srcs: [4]\n",
      "morphs: 概念 と, dst: 9, srcs: []\n",
      "morphs: 『 コンピュータ, dst: 8, srcs: []\n",
      "morphs: （ ） 』 という, dst: 9, srcs: [7]\n",
      "morphs: 道具 を, dst: 10, srcs: [5, 6, 8]\n",
      "morphs: 用い て, dst: 12, srcs: [9]\n",
      "morphs: 『 知能 』 を, dst: 12, srcs: []\n",
      "morphs: 研究 する, dst: 13, srcs: [10, 11]\n",
      "morphs: 計算 機 科学, dst: 14, srcs: [12]\n",
      "morphs: （ ） の, dst: 15, srcs: [13]\n",
      "morphs: 一 分野 」 を, dst: 16, srcs: [14]\n",
      "morphs: 指す, dst: 17, srcs: [15]\n",
      "morphs: 語 。, dst: 34, srcs: [0, 1, 3, 16]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences_c = []\n",
    "s = []\n",
    "srcs_dict = {0:[]}\n",
    "morphs = []\n",
    "chunk = Chunk(0)\n",
    "reset_s = False # to reset variables for new sentence\n",
    "reset_index = False # to reset variables for new paragraph\n",
    "index = -1\n",
    "\n",
    "# sentences_c: [[s1], [s2], ...] or [[c11 c12 ...], [c21 c22 ...], ...]\n",
    "for line in lines: \n",
    "    if re.search(r\"^\\*.*\", line):\n",
    "        # append previously finished chunk to s\n",
    "        # avoid doing this with the first line\n",
    "        if index >= 0:\n",
    "            if index in srcs_dict.keys():\n",
    "                s.append( Chunk(index=index, morphs=morphs, dst=dst, srcs=srcs_dict[index]) )\n",
    "            else:\n",
    "                s.append( Chunk(index=index, morphs=morphs, dst=dst) )\n",
    "            morphs = []\n",
    "            \n",
    "        # if to begin new sentence: append the current one and then reset variables\n",
    "        if reset_s:\n",
    "            if len(s)!=0:\n",
    "                sentences_c.append(s)\n",
    "            s = []\n",
    "            reset_s = False\n",
    "        \n",
    "        if reset_index:\n",
    "            srcs_dict = {0:[]}\n",
    "            reset_index = False\n",
    "                \n",
    "        # collect index, dst value from \"* [index] [dst]D ...\"\n",
    "        m = re.search(r\"(?<=\\*\\s)(?P<index>(\\d)+)\\s(?P<dst>(-)?(\\d)+).*\", line)\n",
    "        index = int(m.group(\"index\"))\n",
    "        dst = int(m.group(\"dst\"))\n",
    "        \n",
    "        # update srcs_dict\n",
    "        if dst in srcs_dict.keys():\n",
    "            srcs_dict[dst].append(index)\n",
    "        else:\n",
    "            srcs_dict[dst] = [index]\n",
    "            \n",
    "    elif line == \"EOS\":\n",
    "        reset_s = True\n",
    "        reset_index = True # chunk index will be recounting from 0\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        # add info to Chunk obj (morphs)\n",
    "        cols = re.split(r\"\\t|,\", line)\n",
    "        morphs.append(Morph(cols[0],cols[7],cols[1],cols[2]))\n",
    "        \n",
    "        if cols[0] == \"。\":\n",
    "            reset_s = True\n",
    "            \n",
    "# last line\n",
    "if index in srcs_dict.keys():\n",
    "    s.append( Chunk(index=index, morphs=morphs, dst=dst, srcs=srcs_dict[index]) )\n",
    "else:\n",
    "    s.append( Chunk(index=index, morphs=morphs, dst=dst) )\n",
    "    morphs = []\n",
    "\n",
    "if len(s)!=0:\n",
    "    sentences_c.append(s)\n",
    "\n",
    "# 確認\n",
    "for sentence in sentences_c[:2]:\n",
    "    for chunk in sentence:\n",
    "        print(chunk)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e69161-15e1-4c54-ad8e-0bb5dffcf5c7",
   "metadata": {},
   "source": [
    "### 42. 係り元と係り先の文節の表示\n",
    "係り元の文節と係り先の文節のテキストをタブ区切り形式ですべて抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cbc2da7-ce0d-4e7f-8453-24a56af085b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "人工知能\t \n",
      "人工知能\t語\n",
      "じんこうちのう\t語\n",
      "AI\tエーアイとは\n",
      "エーアイとは\t語\n",
      "計算\tという\n",
      "という\t道具を\n",
      "概念と\t道具を\n",
      "コンピュータ\tという\n",
      "という\t道具を\n",
      "道具を\t用いて\n",
      "用いて\t研究する\n",
      "知能を\t研究する\n",
      "研究する\t計算機科学\n",
      "計算機科学\tの\n",
      "の\t一分野を\n",
      "一分野を\t指す\n",
      "指す\t語\n",
      "語\t研究分野とも\n"
     ]
    }
   ],
   "source": [
    "phrases_pair= []\n",
    "phrases = dict() # phrase of each index\n",
    "i_pair = [] # pairs of (src, dst) indices\n",
    "\n",
    "for sentence in sentences_c:\n",
    "    for chunk in sentence:\n",
    "        i_pair.append((chunk.index, chunk.dst))\n",
    "        # extract phrase\n",
    "        p = \"\".join([morph.surface for morph in chunk.morphs if morph.pos!=\"記号\"])\n",
    "        phrases[chunk.index] = p\n",
    "        \n",
    "        if chunk.dst == -1:\n",
    "            # append phrases_pair\n",
    "            phrases[-1] = \" \" # dst=-1: phrases[-1] will be null string\n",
    "            for i in i_pair:\n",
    "                phrases_pair.append(phrases[i[0]]+\"\\t\"+phrases[i[1]])\n",
    "                \n",
    "            # reset phrases and i_pair\n",
    "            phrases = dict()\n",
    "            i_pair = []\n",
    "\n",
    "# first sentence\n",
    "# 人工知能（じんこうちのう、、AI〈エーアイ〉）とは、「『計算（）』という概念と『コンピュータ（）』という道具を用いて『知能』を研究する計算機科学（）の一分野」を指す語。\n",
    "for p in phrases_pair[:19]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95118746-798c-47f3-8233-69e7398dd384",
   "metadata": {},
   "source": [
    "### 43. 名詞を含む文節が動詞を含む文節に係るものを抽出\n",
    "名詞を含む文節が，動詞を含む文節に係るとき，これらをタブ区切り形式で抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beb6cf22-1b8b-4f35-ac2e-792e2e697ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "道具を\t用いて\n",
      "知能を\t研究する\n",
      "一分野を\t指す\n",
      "知的行動を\t代わって\n",
      "人間に\t代わって\n",
      "コンピューターに\t行わせる\n",
      "研究分野とも\tされる\n"
     ]
    }
   ],
   "source": [
    "phrases_pair_NV = []\n",
    "phrases = dict() # {index: (phrase, NP/VP/-)}\n",
    "i_pair = [] # pairs of (src, dst) indices\n",
    "\n",
    "for sentence in sentences_c:\n",
    "    for chunk in sentence:\n",
    "        i_pair.append((chunk.index, chunk.dst))\n",
    "        # extract phrase\n",
    "        p = \"\".join([morph.surface for morph in chunk.morphs if morph.pos!=\"記号\"])\n",
    "        pos_list = [morph.pos for morph in chunk.morphs]\n",
    "        kind = \"-\"\n",
    "        if \"動詞\" in pos_list:\n",
    "            kind = \"VP\"\n",
    "        elif \"名詞\" in pos_list:\n",
    "            kind = \"NP\"\n",
    "        # phrases.append((p, kind))\n",
    "        phrases[chunk.index] = (p, kind)\n",
    "        \n",
    "        if chunk.dst == -1:\n",
    "            # append phrases_pair\n",
    "            phrases[-1] = (\" \", \"-\")\n",
    "            for i in i_pair:\n",
    "                if phrases[i[0]][1]==\"NP\" and phrases[i[1]][1]==\"VP\":\n",
    "                    phrases_pair_NV.append(phrases[i[0]][0]+\"\\t\"+phrases[i[1]][0])\n",
    "                \n",
    "            # reset phrases and i_pair\n",
    "            phrases = dict()\n",
    "            i_pair = []\n",
    "            \n",
    "# first 2 sentences\n",
    "# 人工知能（じんこうちのう、、AI〈エーアイ〉）とは、「『計算（）』という概念と『コンピュータ（）』という道具を用いて『知能』を研究する計算機科学（）の一分野」を指す語。\n",
    "#「言語の理解や推論、問題解決などの知的行動を人間に代わってコンピューターに行わせる技術」、または、「計算機（コンピュータ）による知的な情報処理システムの設計や実現に関する研究分野」ともされる。\n",
    "for p in phrases_pair_NV[:7]:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fca93c-4060-4f49-b517-60e030b2017a",
   "metadata": {},
   "source": [
    "### 44. 係り受け木の可視化\n",
    "与えられた文の係り受け木を有向グラフとして可視化せよ．可視化には，Graphviz等を用いるとよい．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8c7f9e6-6064-410d-9a3d-b0ec8e6b4be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def visualize(sentence):\n",
    "    graph = Digraph(format=\"png\", strict=True)\n",
    "    phrases = dict() # phrase of each index\n",
    "    i_pair = [] # pairs of (src, dst) indices\n",
    "    threshold = sentence[0].index + len(sentence) \n",
    "\n",
    "    for chunk in sentence:\n",
    "        i_pair.append((chunk.index, chunk.dst))\n",
    "        # extract phrase\n",
    "        p = \"\".join([morph.surface for morph in chunk.morphs if morph.pos!=\"記号\"])\n",
    "        phrases[chunk.index] = p\n",
    "        graph.node(p)\n",
    "        \n",
    "    # append phrases_pair\n",
    "    for i in i_pair:\n",
    "        if i[1] > -1 and i[1] < threshold: # ignore when dst not in this sentence\n",
    "            graph.edge(phrases[i[0]], phrases[i[1]])\n",
    "            \n",
    "    graph.render(\"images/out_44\")\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23f70f7c-e8c6-47f9-8aca-822796f15a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 3.0.0 (20220226.1711)\n -->\n<!-- Pages: 1 -->\n<svg width=\"553pt\" height=\"692pt\"\n viewBox=\"0.00 0.00 553.44 692.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 688)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-688 549.44,-688 549.44,4 -4,4\"/>\n<!-- 人工知能 -->\n<g id=\"node1\" class=\"node\">\n<title>人工知能</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"48.1\" cy=\"-90\" rx=\"48.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"48.1\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">人工知能</text>\n</g>\n<!-- 語 -->\n<g id=\"node17\" class=\"node\">\n<title>語</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"268.1\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"268.1\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">語</text>\n</g>\n<!-- 人工知能&#45;&gt;語 -->\n<g id=\"edge1\" class=\"edge\">\n<title>人工知能&#45;&gt;語</title>\n<path fill=\"none\" stroke=\"black\" d=\"M83.44,-77.75C124.98,-64.54 193.42,-42.76 234.29,-29.76\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"235.58,-33.02 244.05,-26.65 233.46,-26.35 235.58,-33.02\"/>\n</g>\n<!-- じんこうちのう -->\n<g id=\"node2\" class=\"node\">\n<title>じんこうちのう</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"189.1\" cy=\"-90\" rx=\"75.29\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"189.1\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">じんこうちのう</text>\n</g>\n<!-- じんこうちのう&#45;&gt;語 -->\n<g id=\"edge2\" class=\"edge\">\n<title>じんこうちのう&#45;&gt;語</title>\n<path fill=\"none\" stroke=\"black\" d=\"M207.82,-72.41C218.87,-62.62 232.94,-50.15 244.72,-39.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"247.27,-42.13 252.43,-32.88 242.63,-36.89 247.27,-42.13\"/>\n</g>\n<!-- AI -->\n<g id=\"node3\" class=\"node\">\n<title>AI</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"347.1\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"347.1\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">AI</text>\n</g>\n<!-- エーアイとは -->\n<g id=\"node4\" class=\"node\">\n<title>エーアイとは</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"347.1\" cy=\"-90\" rx=\"64.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"347.1\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">エーアイとは</text>\n</g>\n<!-- AI&#45;&gt;エーアイとは -->\n<g id=\"edge3\" class=\"edge\">\n<title>AI&#45;&gt;エーアイとは</title>\n<path fill=\"none\" stroke=\"black\" d=\"M347.1,-143.7C347.1,-135.98 347.1,-126.71 347.1,-118.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"350.6,-118.1 347.1,-108.1 343.6,-118.1 350.6,-118.1\"/>\n</g>\n<!-- エーアイとは&#45;&gt;語 -->\n<g id=\"edge4\" class=\"edge\">\n<title>エーアイとは&#45;&gt;語</title>\n<path fill=\"none\" stroke=\"black\" d=\"M328.37,-72.41C317.33,-62.62 303.25,-50.15 291.47,-39.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"293.56,-36.89 283.76,-32.88 288.92,-42.13 293.56,-36.89\"/>\n</g>\n<!-- 計算 -->\n<g id=\"node5\" class=\"node\">\n<title>計算</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"309.1\" cy=\"-666\" rx=\"29.5\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"309.1\" y=\"-662.3\" font-family=\"Times,serif\" font-size=\"14.00\">計算</text>\n</g>\n<!-- という -->\n<g id=\"node6\" class=\"node\">\n<title>という</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"365.1\" cy=\"-594\" rx=\"38.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"365.1\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">という</text>\n</g>\n<!-- 計算&#45;&gt;という -->\n<g id=\"edge5\" class=\"edge\">\n<title>計算&#45;&gt;という</title>\n<path fill=\"none\" stroke=\"black\" d=\"M321.52,-649.46C328.67,-640.53 337.81,-629.11 345.87,-619.04\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"348.8,-620.97 352.31,-610.98 343.33,-616.6 348.8,-620.97\"/>\n</g>\n<!-- 道具を -->\n<g id=\"node9\" class=\"node\">\n<title>道具を</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"412.1\" cy=\"-522\" rx=\"38.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"412.1\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">道具を</text>\n</g>\n<!-- という&#45;&gt;道具を -->\n<g id=\"edge6\" class=\"edge\">\n<title>という&#45;&gt;道具を</title>\n<path fill=\"none\" stroke=\"black\" d=\"M376.23,-576.41C381.97,-567.87 389.08,-557.28 395.45,-547.79\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"398.37,-549.72 401.04,-539.47 392.56,-545.82 398.37,-549.72\"/>\n</g>\n<!-- 概念と -->\n<g id=\"node7\" class=\"node\">\n<title>概念と</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"460.1\" cy=\"-594\" rx=\"38.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"460.1\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">概念と</text>\n</g>\n<!-- 概念と&#45;&gt;道具を -->\n<g id=\"edge7\" class=\"edge\">\n<title>概念と&#45;&gt;道具を</title>\n<path fill=\"none\" stroke=\"black\" d=\"M448.96,-576.76C443.11,-568.23 435.81,-557.58 429.25,-548.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"432.04,-545.9 423.5,-539.63 426.27,-549.86 432.04,-545.9\"/>\n</g>\n<!-- コンピュータ -->\n<g id=\"node8\" class=\"node\">\n<title>コンピュータ</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"422.1\" cy=\"-666\" rx=\"65.79\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"422.1\" y=\"-662.3\" font-family=\"Times,serif\" font-size=\"14.00\">コンピュータ</text>\n</g>\n<!-- コンピュータ&#45;&gt;という -->\n<g id=\"edge8\" class=\"edge\">\n<title>コンピュータ&#45;&gt;という</title>\n<path fill=\"none\" stroke=\"black\" d=\"M408.3,-648.05C401.26,-639.42 392.59,-628.76 384.86,-619.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"387.4,-616.85 378.37,-611.31 381.97,-621.27 387.4,-616.85\"/>\n</g>\n<!-- 用いて -->\n<g id=\"node10\" class=\"node\">\n<title>用いて</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"412.1\" cy=\"-450\" rx=\"38.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"412.1\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">用いて</text>\n</g>\n<!-- 道具を&#45;&gt;用いて -->\n<g id=\"edge9\" class=\"edge\">\n<title>道具を&#45;&gt;用いて</title>\n<path fill=\"none\" stroke=\"black\" d=\"M412.1,-503.7C412.1,-495.98 412.1,-486.71 412.1,-478.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"415.6,-478.1 412.1,-468.1 408.6,-478.1 415.6,-478.1\"/>\n</g>\n<!-- 研究する -->\n<g id=\"node12\" class=\"node\">\n<title>研究する</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"459.1\" cy=\"-378\" rx=\"48.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"459.1\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">研究する</text>\n</g>\n<!-- 用いて&#45;&gt;研究する -->\n<g id=\"edge10\" class=\"edge\">\n<title>用いて&#45;&gt;研究する</title>\n<path fill=\"none\" stroke=\"black\" d=\"M423.23,-432.41C428.83,-424.08 435.73,-413.8 441.98,-404.49\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"445.04,-406.21 447.71,-395.96 439.23,-402.31 445.04,-406.21\"/>\n</g>\n<!-- 知能を -->\n<g id=\"node11\" class=\"node\">\n<title>知能を</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"507.1\" cy=\"-450\" rx=\"38.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"507.1\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">知能を</text>\n</g>\n<!-- 知能を&#45;&gt;研究する -->\n<g id=\"edge11\" class=\"edge\">\n<title>知能を&#45;&gt;研究する</title>\n<path fill=\"none\" stroke=\"black\" d=\"M495.96,-432.76C490.11,-424.23 482.81,-413.58 476.25,-404.02\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"479.04,-401.9 470.5,-395.63 473.27,-405.86 479.04,-401.9\"/>\n</g>\n<!-- 計算機科学 -->\n<g id=\"node13\" class=\"node\">\n<title>計算機科学</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"459.1\" cy=\"-306\" rx=\"57.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"459.1\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">計算機科学</text>\n</g>\n<!-- 研究する&#45;&gt;計算機科学 -->\n<g id=\"edge12\" class=\"edge\">\n<title>研究する&#45;&gt;計算機科学</title>\n<path fill=\"none\" stroke=\"black\" d=\"M459.1,-359.7C459.1,-351.98 459.1,-342.71 459.1,-334.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"462.6,-334.1 459.1,-324.1 455.6,-334.1 462.6,-334.1\"/>\n</g>\n<!-- の -->\n<g id=\"node14\" class=\"node\">\n<title>の</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"459.1\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"459.1\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">の</text>\n</g>\n<!-- 計算機科学&#45;&gt;の -->\n<g id=\"edge13\" class=\"edge\">\n<title>計算機科学&#45;&gt;の</title>\n<path fill=\"none\" stroke=\"black\" d=\"M459.1,-287.7C459.1,-279.98 459.1,-270.71 459.1,-262.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"462.6,-262.1 459.1,-252.1 455.6,-262.1 462.6,-262.1\"/>\n</g>\n<!-- 一分野を -->\n<g id=\"node15\" class=\"node\">\n<title>一分野を</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"459.1\" cy=\"-162\" rx=\"48.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"459.1\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">一分野を</text>\n</g>\n<!-- の&#45;&gt;一分野を -->\n<g id=\"edge14\" class=\"edge\">\n<title>の&#45;&gt;一分野を</title>\n<path fill=\"none\" stroke=\"black\" d=\"M459.1,-215.7C459.1,-207.98 459.1,-198.71 459.1,-190.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"462.6,-190.1 459.1,-180.1 455.6,-190.1 462.6,-190.1\"/>\n</g>\n<!-- 指す -->\n<g id=\"node16\" class=\"node\">\n<title>指す</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"459.1\" cy=\"-90\" rx=\"29.5\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"459.1\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">指す</text>\n</g>\n<!-- 一分野を&#45;&gt;指す -->\n<g id=\"edge15\" class=\"edge\">\n<title>一分野を&#45;&gt;指す</title>\n<path fill=\"none\" stroke=\"black\" d=\"M459.1,-143.7C459.1,-135.98 459.1,-126.71 459.1,-118.11\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"462.6,-118.1 459.1,-108.1 455.6,-118.1 462.6,-118.1\"/>\n</g>\n<!-- 指す&#45;&gt;語 -->\n<g id=\"edge16\" class=\"edge\">\n<title>指す&#45;&gt;語</title>\n<path fill=\"none\" stroke=\"black\" d=\"M436.12,-78.64C430.88,-76.38 425.32,-74.05 420.1,-72 379.88,-56.25 332.83,-40.2 301.85,-29.96\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"302.59,-26.51 291.99,-26.71 300.4,-33.16 302.59,-26.51\"/>\n</g>\n</g>\n</svg>\n",
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x104cde580>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = visualize(sentences_c[1])\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d790fb0-3f2c-491f-a392-1ea49d320fc8",
   "metadata": {},
   "source": [
    "### 45. 動詞の格パターンの抽出\n",
    "今回用いている文章をコーパスと見なし，日本語の述語が取りうる格を調査したい． 動詞を述語，動詞に係っている文節の助詞を格と考え，述語と格をタブ区切り形式で出力せよ． ただし，出力は以下の仕様を満たすようにせよ．\n",
    "\n",
    "- 動詞を含む文節において，最左の動詞の基本形を述語とする\n",
    "- 述語に係る助詞を格とする\n",
    "- 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． この文は「作り出す」という１つの動詞を含み，「作り出す」に係る文節は「ジョン・マッカーシーは」，「会議で」，「用語を」であると解析された場合は，次のような出力になるはずである．\n",
    "\n",
    "作り出す\tで は を\n",
    "\n",
    "このプログラムの出力をファイルに保存し，以下の事項をUNIXコマンドを用いて確認せよ．\n",
    "\n",
    "- コーパス中で頻出する述語と格パターンの組み合わせ\n",
    "- 「行う」「なる」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順に並べよ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c737bc2d-e7d1-4721-9dc3-7f3c61690910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 述語\\t格\n",
    "# 動詞\\t助詞1 助詞2 ... \n",
    "\n",
    "with open(\"out_45.txt\", \"w\") as f:\n",
    "    for sentence in sentences_c:\n",
    "        for chunk in sentence:\n",
    "            # find all 動詞\n",
    "            pos_list = [morph.pos for morph in chunk.morphs]\n",
    "            if \"動詞\" in pos_list:\n",
    "                V_i = pos_list.index(\"動詞\") # only the first 動詞's index\n",
    "                verb = chunk.morphs[V_i].base\n",
    "                \n",
    "                # find src of the 動詞\n",
    "                # get 助詞 from all src\n",
    "                src_chunks = [c for c in sentence if c.index in chunk.srcs]\n",
    "                par_list = []\n",
    "                for c in src_chunks:\n",
    "                    pars = [m.base for m in c.morphs if m.pos==\"助詞\"]\n",
    "                    if len(pars) > 0:\n",
    "                        # par = \"\".join(pars) # if include 連結助詞：での、には、のに...\n",
    "                        par = pars[-1] # only the last 助詞\n",
    "                        par_list.append(par)\n",
    "                if len(par_list) > 0:\n",
    "                    line = \"\\t\".join([verb, \" \".join(set(sorted(par_list)))]) # 日本語の辞書順じゃないかも...\n",
    "                    f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "026dc465-6417-4842-b390-bdba98a96504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用いる\tを\n",
      "する\tを て\n",
      "指す\tを\n",
      "代わる\tに を\n",
      "行う\tに て\n",
      "する\tも\n",
      "述べる\tに は で\n",
      "する\tを で\n",
      "する\tを\n",
      "する\tを\n"
     ]
    }
   ],
   "source": [
    "!cat out_45.txt | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "661f1e8b-f2cd-430a-afaf-b9aba994505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  52 する\tを\n",
      "  22 する\tが\n",
      "  21 する\tと\n",
      "  17 する\tに\n",
      "  14 する\tは を\n",
      "  11 よる\tに\n",
      "  10 する\tに を\n",
      "   9 する\tを で\n",
      "   8 行う\tを\n",
      "   8 する\tは と\n"
     ]
    }
   ],
   "source": [
    "!cat out_45.txt | sort | uniq -c | sort -nr | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f2ad85c-c43f-4497-b908-02a56c7e0fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8 行う\tを\n",
      "   1 行う\tを まで\n",
      "   1 行う\tを で\n",
      "   1 行う\tを て\n",
      "   1 行う\tは を をめぐって\n",
      "   1 行う\tは を\n",
      "   1 行う\tは で が\n",
      "   1 行う\tは が\n",
      "   1 行う\tは\n",
      "   1 行う\tに を により\n",
      "   1 行う\tに を で\n",
      "   1 行う\tに を て\n",
      "   1 行う\tに を\n",
      "   1 行う\tに まで を\n",
      "   1 行う\tに て は が\n",
      "   1 行う\tに て\n",
      "   1 行う\tに\n",
      "   1 行う\tから\n"
     ]
    }
   ],
   "source": [
    "!cat out_45.txt | sort | uniq -c | sort -nr | grep \"行う\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99c433aa-fb8a-4cbe-a2fa-3e07c04ae9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4 なる\tに は\n",
      "   4 なる\tと が\n",
      "   2 なる\tに\n",
      "   2 なる\tと\n",
      "   1 異なる\tも\n",
      "   1 異なる\tで が\n",
      "   1 無くなる\tは\n",
      "   1 なる\tも\n",
      "   1 なる\tは も\n",
      "   1 なる\tは にとって が\n",
      "   1 なる\tは で\n",
      "   1 なる\tは\n",
      "   1 なる\tに は で\n",
      "   1 なる\tに は が\n",
      "   1 なる\tに として て は\n",
      "   1 なる\tに が\n",
      "   1 なる\tなど は と\n",
      "   1 なる\tと に で は が\n",
      "   1 なる\tと て は から が\n",
      "   1 なる\tで と から\n"
     ]
    }
   ],
   "source": [
    "!cat out_45.txt | sort | uniq -c | sort -nr | grep \"なる\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "450855b7-a26d-412b-abf8-2e188aefba45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2 与える\tに が\n",
      "   1 与える\tに を は\n"
     ]
    }
   ],
   "source": [
    "!cat out_45.txt | sort | uniq -c | sort -nr | grep \"与える\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef6e264-a0e0-4964-b9fe-b526432f5038",
   "metadata": {},
   "source": [
    "### 46. 動詞の格フレーム情報の抽出\n",
    "45のプログラムを改変し，述語と格パターンに続けて項（述語に係っている文節そのもの）をタブ区切り形式で出力せよ．45の仕様に加えて，以下の仕様を満たすようにせよ．\n",
    "\n",
    "- 項は述語に係っている文節の単語列とする（末尾の助詞を取り除く必要はない）\n",
    "- 述語に係る文節が複数あるときは，助詞と同一の基準・順序でスペース区切りで並べる\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． この文は「作り出す」という１つの動詞を含み，「作り出す」に係る文節は「ジョン・マッカーシーは」，「会議で」，「用語を」であると解析された場合は，次のような出力になるはずである．\n",
    "\n",
    "作り出す\tで は を\t会議で ジョンマッカーシーは 用語を"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3465c8fa-9b11-490b-a863-1200f40476fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 動詞\\t助詞1 助詞2 ... \\t 文節1 文節2 ...\n",
    "\n",
    "with open(\"out_46.txt\", \"w\") as f:\n",
    "    for sentence in sentences_c:\n",
    "        for chunk in sentence:\n",
    "            # find all 動詞\n",
    "            pos_list = [morph.pos for morph in chunk.morphs]\n",
    "            if \"動詞\" in pos_list:\n",
    "                V_i = pos_list.index(\"動詞\") # only the first 動詞's index\n",
    "                verb = chunk.morphs[V_i].base\n",
    "                \n",
    "                # find src of the 動詞\n",
    "                # get 助詞 from all src\n",
    "                src_chunks = [c for c in sentence if c.index in chunk.srcs]\n",
    "                par_chunk = [] # store tuples of (助詞, 項)\n",
    "                for c in src_chunks:\n",
    "                    pars = [m.base for m in c.morphs if m.pos==\"助詞\"]\n",
    "                    if len(pars) > 0:\n",
    "                        i = [m.surface for m in c.morphs].index(pars[-1])\n",
    "                        par_chunk.append( (pars[-1], \"\".join([morph.surface for morph in c.morphs[:i+1] if morph.pos!=\"記号\"])) ) # (助詞, 項)\n",
    "                if len(par_chunk) > 0:\n",
    "                    par_chunk = sorted(par_chunk, key=lambda x: x[0]) # 日本語の辞書順じゃないかも...\n",
    "                    line = \"\\t\".join([verb, \" \".join([x[0] for x in par_chunk]), \" \".join([x[1] for x in par_chunk])])\n",
    "                    f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74af4159-9e32-4f1f-82d6-45f8167c6728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "作り出す\tで は を\t会議で ジョンマッカーシーは 用語を\n"
     ]
    }
   ],
   "source": [
    "!cat out_46.txt | grep \"作り出す\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc949100-b243-48d0-8983-a626f0e9a38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用いる\tを\t道具を\n",
      "する\tて を\t用いて 知能を\n",
      "指す\tを\t一分野を\n",
      "代わる\tに を\t人間に 知的行動を\n",
      "行う\tて に\t代わって コンピューターに\n",
      "する\tも\t研究分野とも\n",
      "述べる\tで に は\t解説で 次のように 佐藤理史は\n",
      "する\tで を\tコンピュータ上で 知的能力を\n",
      "する\tを\t推論判断を\n",
      "する\tを\t画像データを\n"
     ]
    }
   ],
   "source": [
    "!cat out_46.txt | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b212f9-6f90-4441-b4fd-bff097390f0c",
   "metadata": {},
   "source": [
    "### 47. 機能動詞構文のマイニング\n",
    "動詞のヲ格にサ変接続名詞が入っている場合のみに着目したい．46のプログラムを以下の仕様を満たすように改変せよ．\n",
    "\n",
    "- 「サ変接続名詞+を（助詞）」で構成される文節が動詞に係る場合のみを対象とする\n",
    "- 述語は「サ変接続名詞+を+動詞の基本形」とし，文節中に複数の動詞があるときは，最左の動詞を用いる\n",
    "- 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n",
    "- 述語に係る文節が複数ある場合は，すべての項をスペース区切りで並べる（助詞の並び順と揃えよ）\n",
    "例えば「また、自らの経験を元に学習を行う強化学習という手法もある。」という文から，以下の出力が得られるはずである．\n",
    "\n",
    "学習を行う\tに を\t元に 経験を\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d89ea0d2-05bb-4802-b33d-1bcd1615dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# サ変接続名詞 = N+する できる名詞 (pos1=\"サ変接続\")\n",
    "# 「サ変接続名詞+を+動詞の基本形」\\t 助詞1 助詞2 ... \\t 文節1 文節2 ...\n",
    "# 前提：「サ変接続名詞+を」が（例のように）複数ある場合は最右のものを選ぶ\n",
    "\n",
    "with open(\"out_47.txt\", \"w\") as f:\n",
    "    for sentence in sentences_c:\n",
    "        for chunk in sentence:\n",
    "            # find all 動詞\n",
    "            pos_list = [morph.pos for morph in chunk.morphs]\n",
    "            if \"動詞\" in pos_list:\n",
    "                V_i = pos_list.index(\"動詞\") # only the first 動詞's index\n",
    "                verb = chunk.morphs[V_i].base\n",
    "                is_valid = False\n",
    "                \n",
    "                # find all src of the 動詞\n",
    "                src_chunks = [c for c in sentence if c.index in chunk.srcs]\n",
    "                par_chunk = []\n",
    "                for c in src_chunks:\n",
    "                    # check for「サ変接続名詞+を」/ keep only the last noun_wo\n",
    "                    i_sa = [i for i in range(len(c.morphs)-1) if c.morphs[i].pos1==\"サ変接続\" and c.morphs[i+1].surface==\"を\"]\n",
    "                    if len(i_sa) > 0: # should be == 1\n",
    "                        is_valid = True\n",
    "                        noun_wo = c.morphs[i_sa[0]].surface + c.morphs[i_sa[0]+1].surface # update the last noun_wo\n",
    "                    \n",
    "                    pars = [m.base for m in c.morphs if m.pos==\"助詞\"]   \n",
    "                    if len(pars) > 0:\n",
    "                        i = [m.surface for m in c.morphs].index(pars[-1])\n",
    "                        par_chunk.append( (pars[-1], \"\".join([morph.surface for morph in c.morphs[:i+1] if morph.pos!=\"記号\"])) )\n",
    "                   \n",
    "                # write into file if it is the valid verb (satisfy all cond.)\n",
    "                if is_valid and len(par_chunk) > 0:\n",
    "                    par_chunk = sorted(par_chunk, key=lambda x: x[0]) # 日本語の辞書順じゃないかも...\n",
    "                    # exclude the noun_wo from par_chunk\n",
    "                    for pc in par_chunk:\n",
    "                        if pc[0]==\"を\" and noun_wo in pc[1]:\n",
    "                            par_chunk.remove(pc)\n",
    "\n",
    "                    line = \"\\t\".join([noun_wo+verb, \" \".join([x[0] for x in par_chunk]), \" \".join([x[1] for x in par_chunk])])\n",
    "                    f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "701d7f9b-bc7a-4968-a94c-c3cebabfa67d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "行動を代わる\tに\t人間に\n",
      "判断をする\t\t\n",
      "処理を用いる\t\t\n",
      "記述をする\tと\t主体と\n",
      "注目を集める\tが\tサポートベクターマシンが\n",
      "学習を行う\tに を\t元に 経験を\n",
      "流行を超える\t\t\n",
      "学習を繰り返す\t\t\n",
      "学習をする\tに は を を通して\t元に ACT-Rでは 推論ルールを 生成規則を通して\n",
      "進化を見せる\tて において は\t加えて 生成技術において 敵対的生成ネットワークは\n"
     ]
    }
   ],
   "source": [
    "!cat out_47.txt | head -n 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06cd27e4-df60-45d2-a52f-9bfee0a3801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "学習を行う\tに を\t元に 経験を\n"
     ]
    }
   ],
   "source": [
    "!cat out_47.txt | grep \"学習を行う\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412e0c9-148b-47a2-8176-eaae4ed763df",
   "metadata": {},
   "source": [
    "### 48. 名詞から根へのパスの抽出\n",
    "文中のすべての名詞を含む文節に対し，その文節から構文木の根に至るパスを抽出せよ． ただし，構文木上のパスは以下の仕様を満たすものとする．\n",
    "\n",
    "- 各文節は（表層形の）形態素列で表現する\n",
    "- パスの開始文節から終了文節に至るまで，各文節の表現を” -> “で連結する\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． CaboChaを係り受け解析に用いた場合，次のような出力が得られると思われる．\n",
    "\n",
    "```\n",
    "ジョンマッカーシーは -> 作り出した\n",
    "AIに関する -> 最初の -> 会議で -> 作り出した\n",
    "最初の -> 会議で -> 作り出した\n",
    "会議で -> 作り出した\n",
    "人工知能という -> 用語を -> 作り出した\n",
    "用語を -> 作り出した\n",
    "```\n",
    "\n",
    "KNPを係り受け解析に用いた場合，次のような出力が得られると思われる\n",
    "\n",
    "```\n",
    "ジョンマッカーシーは -> 作り出した\n",
    "ＡＩに -> 関する -> 会議で -> 作り出した\n",
    "会議で -> 作り出した\n",
    "人工知能と -> いう -> 用語を -> 作り出した\n",
    "用語を -> 作り出した\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c01e6b65-e226-4816-98e8-3ddfda5f57c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根=文末 とする (!= chunk that dst=-1 (段落の末) )\n",
    "with open(\"out_48.txt\", \"w\") as f:\n",
    "    for sentence in sentences_c:\n",
    "        if len(sentence) == 1: # a title\n",
    "            continue\n",
    "        offset = sentence[0].index\n",
    "        end = offset + len(sentence) - 1\n",
    "        for chunk in sentence:\n",
    "            if \"名詞\" in [m.pos for m in chunk.morphs]:\n",
    "                # find route\n",
    "                route = [\"\".join([m.surface for m in chunk.morphs if m.pos!=\"記号\"])]\n",
    "                dst = chunk.dst\n",
    "                while dst!=-1 and dst<=end:\n",
    "                    next_chunk = sentence[dst-offset]\n",
    "                    route.append(\"\".join([m.surface for m in next_chunk.morphs if m.pos!=\"記号\"]))\n",
    "                    dst = next_chunk.dst\n",
    "                f.write(\" -> \".join(route)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ced4588-0569-4fbb-98c2-61de3f55e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ジョンマッカーシーは -> 作り出した\n",
      "AIに関する -> 最初の -> 会議で -> 作り出した\n",
      "最初の -> 会議で -> 作り出した\n",
      "会議で -> 作り出した\n",
      "人工知能という -> 用語を -> 作り出した\n",
      "用語を -> 作り出した\n"
     ]
    }
   ],
   "source": [
    "!cat out_48.txt | grep \"作り出した\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2bf1f7-17c3-4bf5-ae33-a7c78e468e5b",
   "metadata": {},
   "source": [
    "### 49. 名詞間の係り受けパスの抽出\n",
    "文中のすべての名詞句のペアを結ぶ最短係り受けパスを抽出せよ．ただし，名詞句ペアの文節番号がiとj（i<j）のとき，係り受けパスは以下の仕様を満たすものとする．\n",
    "\n",
    "- 問題48と同様に，パスは開始文節から終了文節に至るまでの各文節の表現（表層形の形態素列）を” -> “で連結して表現する\n",
    "- 文節iとjに含まれる名詞句はそれぞれ，XとYに置換する\n",
    "\n",
    "また，係り受けパスの形状は，以下の2通りが考えられる．\n",
    "\n",
    "- 文節iから構文木の根に至る経路上に文節jが存在する場合: 文節iから文節jのパスを表示\n",
    "- 上記以外で，文節iと文節jから構文木の根に至る経路上で共通の文節kで交わる場合: 文節iから文節kに至る直前のパスと文節jから文節kに至る直前までのパス，文節kの内容を” | “で連結して表示\n",
    "\n",
    "「ジョン・マッカーシーはAIに関する最初の会議で人工知能という用語を作り出した。」という例文を考える． CaboChaを係り受け解析に用いた場合，次のような出力が得られると思われる．\n",
    "\n",
    "```\n",
    "Xは | Yに関する -> 最初の -> 会議で | 作り出した\n",
    "Xは | Yの -> 会議で | 作り出した\n",
    "Xは | Yで | 作り出した\n",
    "Xは | Yという -> 用語を | 作り出した\n",
    "Xは | Yを | 作り出した\n",
    "Xに関する -> Yの\n",
    "Xに関する -> 最初の -> Yで\n",
    "Xに関する -> 最初の -> 会議で | Yという -> 用語を | 作り出した\n",
    "Xに関する -> 最初の -> 会議で | Yを | 作り出した\n",
    "Xの -> Yで\n",
    "Xの -> 会議で | Yという -> 用語を | 作り出した\n",
    "Xの -> 会議で | Yを | 作り出した\n",
    "Xで | Yという -> 用語を | 作り出した\n",
    "Xで | Yを | 作り出した\n",
    "Xという -> Yを\n",
    "```\n",
    "KNPを係り受け解析に用いた場合，次のような出力が得られると思われる．\n",
    "```\n",
    "Xは | Yに -> 関する -> 会議で | 作り出した。\n",
    "Xは | Yで | 作り出した。\n",
    "Xは | Yと -> いう -> 用語を | 作り出した。\n",
    "Xは | Yを | 作り出した。\n",
    "Xに -> 関する -> Yで\n",
    "Xに -> 関する -> 会議で | Yと -> いう -> 用語を | 作り出した。\n",
    "Xに -> 関する -> 会議で | Yを | 作り出した。\n",
    "Xで | Yと -> いう -> 用語を | 作り出した。\n",
    "Xで | Yを | 作り出した。\n",
    "Xと -> いう -> Yを\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70c3dfd4-e40c-47d4-973a-633aea60d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"out_49.txt\", \"w\") as f:\n",
    "    for i_sentence in range(len(sentences_c)):\n",
    "        sentence = sentences_c[i_sentence]\n",
    "        # skip a non-sentence text (titles)\n",
    "        if len(sentence) == 1:\n",
    "            continue\n",
    "            \n",
    "        # prep some vars\n",
    "        offset = sentence[0].index\n",
    "        end = sentence[-1].index\n",
    "        chunks_np = []  # all chunks with 名詞句\n",
    "        for c in sentence:\n",
    "            for m in c.morphs:\n",
    "                if m.pos==\"名詞\":\n",
    "                    chunks_np.append(c)\n",
    "                    break\n",
    "                    \n",
    "        # for each 名詞句ペア\n",
    "        for i in range(len(chunks_np)-1):\n",
    "            for j in range(i+1, len(chunks_np)):\n",
    "                # initialize\n",
    "                route_i = [\"X\"+\"\".join([m.surface for m in chunks_np[i].morphs if m.pos!=\"記号\" and m.pos!=\"名詞\"])]\n",
    "                dst_i = chunks_np[i].dst\n",
    "                route_j = [\"Y\"+\"\".join([m.surface for m in chunks_np[j].morphs if m.pos!=\"記号\" and m.pos!=\"名詞\"])]\n",
    "                dst_j = chunks_np[j].index\n",
    "                \n",
    "                # loop until finding a match\n",
    "                while dst_i != dst_j:\n",
    "                    if dst_i < dst_j:\n",
    "                        if dst_i > end: # dst not in same sentence\n",
    "                            next_chunk_i = [c for s in sentences_c[i_sentence + 1:] for c in s if c.index==dst_i][0]\n",
    "                        else:\n",
    "                            next_chunk_i = sentence[dst_i-offset]\n",
    "                        route_i.append(\"\".join([m.surface for m in next_chunk_i.morphs if m.pos!=\"記号\"]))\n",
    "                        dst_i = next_chunk_i.dst\n",
    "                    else:\n",
    "                        if dst_j > end:\n",
    "                            next_chunk_j = [c for s in sentences_c[i_sentence+1:] for c in s if c.index==dst_j][0]\n",
    "                        else:\n",
    "                            next_chunk_j = sentence[dst_j-offset]\n",
    "                            \n",
    "                        if dst_j != chunks_np[j].index: # skip first dst_j (= chunks_np[j] itself)\n",
    "                            route_j.append(\"\".join([m.surface for m in next_chunk_j.morphs if m.pos!=\"記号\"]))\n",
    "                        dst_j = next_chunk_j.dst\n",
    "                        \n",
    "                # found a match\n",
    "                # i meet j directly\n",
    "                if dst_i == chunks_np[j].index:\n",
    "                    line = \" -> \".join(route_i+route_j)\n",
    "                # i meet j through k\n",
    "                else:\n",
    "                    if dst_i > end:\n",
    "                        chunk_k = [c for s in sentences_c[i_sentence + 1:] for c in s if c.index==dst_i][0]\n",
    "                    else:\n",
    "                        chunk_k = sentence[dst_i-offset]\n",
    "                    phrase_k = \"\".join([m.surface for m in chunk_k.morphs if m.pos!=\"記号\"])\n",
    "                    line = \" | \".join([\" -> \".join(route_i), \" -> \".join(route_j), phrase_k])\n",
    "                    \n",
    "                f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5dc70b1d-33ba-4f91-8ed0-f38a596d305e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xは | Yに関する -> 最初の -> 会議で | 作り出した\n",
      "Xは | Yの -> 会議で | 作り出した\n",
      "Xは | Yで | 作り出した\n",
      "Xは | Yという -> 用語を | 作り出した\n",
      "Xは | Yを | 作り出した\n",
      "Xに関する -> Yの\n",
      "Xに関する -> 最初の -> Yで\n",
      "Xに関する -> 最初の -> 会議で | Yという -> 用語を | 作り出した\n",
      "Xに関する -> 最初の -> 会議で | Yを | 作り出した\n",
      "Xの -> Yで\n",
      "Xの -> 会議で | Yという -> 用語を | 作り出した\n",
      "Xの -> 会議で | Yを | 作り出した\n",
      "Xで | Yという -> 用語を | 作り出した\n",
      "Xで | Yを | 作り出した\n",
      "Xという -> Yを\n"
     ]
    }
   ],
   "source": [
    "!grep -m 1 -A 14 \"作り出した\" out_49.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e4b3d5cc76d527871e757334873acbc48afe69102a5515277c9dd4fbf59a78e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
